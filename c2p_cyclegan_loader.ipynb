{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "scheduled-happiness",
   "metadata": {},
   "source": [
    "# Casual2Professional CycleGan Loader \n",
    "\n",
    "Loads CycleGAN from file and continues testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-circuit",
   "metadata": {},
   "source": [
    "## Imports and Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.data as tf_data\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Imports\n",
    "from cyclegan_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Parameters\n",
    "pic_size = 256\n",
    "read_image_size = (pic_size, pic_size)\n",
    "model_image_size = (pic_size, pic_size, 3)\n",
    "resent_blocks = 9\n",
    "\n",
    "samples_display_size = 10\n",
    "\n",
    "# Image Preprocessing Parameters\n",
    "image_dataset_path = './casual2professional/'\n",
    "\n",
    "autotune = tf.data.experimental.AUTOTUNE\n",
    "buffer_size = 256\n",
    "batch_size = 1\n",
    "\n",
    "# Model Parameters\n",
    "epochs_to_train = 100\n",
    "\n",
    "# Checkpoint parameters\n",
    "epoch_load = 100\n",
    "model_load_file = './c2p_{}_checkpoints/cyclegan_checkpoints.{:03d}'.format(pic_size, epoch_load)\n",
    "checkpoint_filepath = \"./c2p_checkpoints_loader/cyclegan_checkpoints_cont.{epoch:03d}\"\n",
    "\n",
    "# Loss values file\n",
    "loss_value_file = 'loss_values_loader.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-structure",
   "metadata": {},
   "source": [
    "## Load and Convert Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path, size = read_image_size):\n",
    "    data_list = list()\n",
    "    for filename in os.listdir(path):\n",
    "        pixels = load_img(path + filename, target_size = size)\n",
    "        pixels = img_to_array(pixels)\n",
    "        \n",
    "        data_list.append(pixels)\n",
    "    return np.asarray(data_list)\n",
    "\n",
    "def convert_image_to_dataset(image_data, label):\n",
    "    labels = [label] * len(image_data)\n",
    "    image_dataset = tf_data.Dataset.from_tensor_slices((image_data, labels))\n",
    "    \n",
    "    return image_dataset\n",
    "\n",
    "def normalise_img(img):\n",
    "    img = tf.cast(img, dtype = tf.float32)\n",
    "    \n",
    "    # Map values in the range [-1, 1]\n",
    "    return (img / 127.5) - 1.0\n",
    "\n",
    "def preprocess_train_image(img, label):\n",
    "    # Random flip\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    \n",
    "    # Resize to the original size first\n",
    "    img = tf.image.resize(img, [*read_image_size])\n",
    "    \n",
    "    # Random crop to model input_size\n",
    "    img = tf.image.random_crop(img, size = [*model_image_size])\n",
    "    \n",
    "    # Normalise the pixel values in the range [-1, 1]\n",
    "    img = normalise_img(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def preprocess_test_image(img, label):\n",
    "    # Only resizing and normalisation for the test images\n",
    "    img = tf.image.resize(img, [model_image_size[0], model_image_size[1]])\n",
    "    img = normalise_img(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_A = load_images(image_dataset_path + 'trainA/')\n",
    "test_A = load_images(image_dataset_path + 'testA/')\n",
    "\n",
    "train_B = load_images(image_dataset_path + 'trainB/')\n",
    "test_B = load_images(image_dataset_path + 'testB/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-passenger",
   "metadata": {},
   "source": [
    "### Convert to tensor datasets and perform preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image numpy arrays to tf datasets.\n",
    "# Set Domain A as label 0 and Domain B as label 1\n",
    "train_A = convert_image_to_dataset(train_A, 0)\n",
    "test_A = convert_image_to_dataset(test_A, 0)\n",
    "\n",
    "train_B = convert_image_to_dataset(train_B, 1)\n",
    "test_B = convert_image_to_dataset(test_B, 1)\n",
    "\n",
    "train_A = (train_A.map(preprocess_train_image, num_parallel_calls = autotune).cache().shuffle(buffer_size).batch(batch_size))\n",
    "test_A = (test_A.map(preprocess_test_image, num_parallel_calls = autotune).cache().shuffle(buffer_size).batch(batch_size))\n",
    "\n",
    "train_B = (train_B.map(preprocess_train_image, num_parallel_calls = autotune).cache().shuffle(buffer_size).batch(batch_size))\n",
    "test_B = (test_B.map(preprocess_test_image, num_parallel_calls = autotune).cache().shuffle(buffer_size).batch(batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-contest",
   "metadata": {},
   "source": [
    "## Create Empty CycleGAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan_model = create_default_cyclegan_model(resent_blocks, model_image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-florist",
   "metadata": {},
   "source": [
    "## Load Weights to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-rescue",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan_model.load_weights(model_load_file).expect_partial()\n",
    "print('Weights loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-somerset",
   "metadata": {},
   "source": [
    "### Continue Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-settlement",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Continuing to train CycleGAN model from epoch {}...'.format(epoch_load + 1))\n",
    "\n",
    "# Callbacks\n",
    "plotter = GANMonitor(num_img = samples_display_size, test_A = test_A)\n",
    "model_checkpoint_callback = ModelCheckpoint(filepath = checkpoint_filepath, verbose = 1)\n",
    "\n",
    "# Training the model\n",
    "history = cycle_gan_model.fit(tf.data.Dataset.zip((train_A, train_B)), epochs = epochs_to_train, callbacks = [plotter, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-stack",
   "metadata": {},
   "source": [
    "### Export Loss Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss_history = pd.Series(history.history['G_loss'], name = 'G_loss')\n",
    "f_loss_history = pd.Series(history.history['F_loss'], name = 'F_loss')\n",
    "\n",
    "dx_loss_history = pd.Series(history.history['D_X_loss'], name = 'D_X_loss')\n",
    "dy_loss_history = pd.Series(history.history['D_Y_loss'], name = 'D_Y_loss')\n",
    "\n",
    "loss_df = pd.concat([g_loss_history, f_loss_history, dx_loss_history, dy_loss_history], axis = 1)\n",
    "loss_df.to_csv(loss_value_file, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
