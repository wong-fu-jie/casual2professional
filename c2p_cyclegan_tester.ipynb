{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "common-siemens",
   "metadata": {},
   "source": [
    "# Casual2Professional CycleGAN Tester\n",
    "\n",
    "Tests translation of photos using trained CycleGAN model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-circuit",
   "metadata": {},
   "source": [
    "## Imports and Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.data as tf_data\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Imports\n",
    "from cyclegan_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset_path = './casual2professional/'\n",
    "\n",
    "pic_size = 256\n",
    "read_image_size = (pic_size, pic_size)\n",
    "model_image_size = (pic_size, pic_size, 3)\n",
    "resent_blocks = 9\n",
    "\n",
    "autotune = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "buffer_size = 256\n",
    "batch_size = 1\n",
    "\n",
    "# test_sample_size = 10\n",
    "\n",
    "# File to use for the trained model weights\n",
    "test_epoch = 190\n",
    "weight_file = './c2p_{}_checkpoints/cyclegan_checkpoints.{:03d}'.format(pic_size, test_epoch)\n",
    "\n",
    "# Test Translation Output Folder\n",
    "test_image_output_path = './c2p_{}_test_output_epoch_{}/'.format(pic_size, test_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-structure",
   "metadata": {},
   "source": [
    "## Load and Convert Test Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path, size = read_image_size):\n",
    "    data_list = list()\n",
    "    for filename in os.listdir(path):\n",
    "        pixels = load_img(path + filename, target_size = size)\n",
    "        pixels = img_to_array(pixels)\n",
    "        \n",
    "        data_list.append(pixels)\n",
    "    return np.asarray(data_list)\n",
    "\n",
    "def convert_image_to_dataset(image_data, label):\n",
    "    labels = [label] * len(image_data)\n",
    "    image_dataset = tf_data.Dataset.from_tensor_slices((image_data, labels))\n",
    "    \n",
    "    return image_dataset\n",
    "\n",
    "def normalise_img(img):\n",
    "    img = tf.cast(img, dtype = tf.float32)\n",
    "    \n",
    "    # Map values in the range [-1, 1]\n",
    "    return (img / 127.5) - 1.0\n",
    "\n",
    "def preprocess_test_image(img, label):\n",
    "    # Only resizing and normalisation for the test images\n",
    "    img = tf.image.resize(img, [model_image_size[0], model_image_size[1]])\n",
    "    img = normalise_img(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_A = load_images(image_dataset_path + 'testA/')\n",
    "test_B = load_images(image_dataset_path + 'testB/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-passenger",
   "metadata": {},
   "source": [
    "### Convert to tensor datasets and perform preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image numpy arrays to tf datasets.\n",
    "# Set Domain A as label 0 and Domain B as label 1\n",
    "test_A = convert_image_to_dataset(test_A, 0)\n",
    "test_A = (test_A.map(preprocess_test_image, num_parallel_calls = autotune).cache().shuffle(buffer_size).batch(batch_size))\n",
    "\n",
    "test_B = convert_image_to_dataset(test_B, 1)\n",
    "test_B = (test_B.map(preprocess_test_image, num_parallel_calls = autotune).cache().shuffle(buffer_size).batch(batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-parent",
   "metadata": {},
   "source": [
    "## Reload Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-savage",
   "metadata": {},
   "source": [
    "### Create Empty Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_G = get_resnet_generator(name = \"generator_G\", num_residual_blocks = resent_blocks, model_image_size = model_image_size)\n",
    "gen_F = get_resnet_generator(name = \"generator_F\", num_residual_blocks = resent_blocks, model_image_size = model_image_size)\n",
    "\n",
    "disc_X = get_discriminator(name = \"discriminator_X\", model_image_size = model_image_size)\n",
    "disc_Y = get_discriminator(name = \"discriminator_Y\", model_image_size = model_image_size)\n",
    "\n",
    "# Create CycleGAN model\n",
    "cycle_gan_tester = CycleGan(generator_G = gen_G, generator_F = gen_F, discriminator_X = disc_X, discriminator_Y = disc_Y)\n",
    "\n",
    "learn_rate = 2e-4\n",
    "beta_1_value = 0.5\n",
    "\n",
    "# Compile the model\n",
    "cycle_gan_tester.compile(\n",
    "    gen_G_optimizer = Adam(learning_rate = learn_rate, beta_1 = beta_1_value),\n",
    "    gen_F_optimizer = Adam(learning_rate = learn_rate, beta_1 = beta_1_value),\n",
    "    disc_X_optimizer = Adam(learning_rate = learn_rate, beta_1 = beta_1_value),\n",
    "    disc_Y_optimizer = Adam(learning_rate = learn_rate, beta_1 = beta_1_value),\n",
    "    gen_loss_fn = generator_loss_fn,\n",
    "    disc_loss_fn = discriminator_loss_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-coverage",
   "metadata": {},
   "source": [
    "### Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan_tester.load_weights(weight_file).expect_partial()\n",
    "print('Weights loaded successfully. Generating translation with test images...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-bunny",
   "metadata": {},
   "source": [
    "## Translate Test Pictures with Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_output_dir(folder_path):\n",
    "    if not os.path.exists(test_image_output_path):\n",
    "        os.makedirs(test_image_output_path)\n",
    "\n",
    "def plot_save_translation_pair(image, translated, folder_path, epoch, iteration):\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (5, 3))\n",
    "    \n",
    "    ax[0].axis('off')\n",
    "    ax[0].imshow(image)\n",
    "    \n",
    "    ax[1].axis('off')\n",
    "    ax[1].imshow(translated)\n",
    "    \n",
    "    plt.savefig('{}/epoch_{}_pic_{}.png'.format(folder_path, epoch, iteration))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-compilation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Currently only testing for A to B\n",
    "\n",
    "make_image_output_dir(test_image_output_path)\n",
    "\n",
    "for i, img in enumerate(test_A):\n",
    "    predict = cycle_gan_tester.gen_G(img)[0].numpy()\n",
    "    predict = ((predict * 127.5) + 127.5).astype(np.uint8)\n",
    "    img = ((img[0] * 127.5) + 127.5).numpy().astype(np.uint8)\n",
    "    \n",
    "    plot_save_translation_pair(img, predict, test_image_output_path, test_epoch, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
